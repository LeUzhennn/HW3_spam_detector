
import streamlit as st
import pandas as pd
import joblib
import string
import os

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="åƒåœ¾éƒµä»¶é æ¸¬ç³»çµ±", page_icon="ğŸ“§")
st.title("ğŸ“§ åƒåœ¾éƒµä»¶(Spam)é æ¸¬ç³»çµ±")
st.write("é€™æ˜¯ä¸€å€‹ä½¿ç”¨ Naive Bayes æ¨¡å‹å»ºç«‹çš„åƒåœ¾éƒµä»¶åˆ†é¡å™¨ã€‚æ‚¨å¯ä»¥è¼¸å…¥æ–‡å­—ï¼Œæˆ–éš¨æ©Ÿå¾è³‡æ–™é›†ä¸­æŠ½æ¨£ï¼Œä¾†æ¸¬è©¦æ¨¡å‹çš„æ•ˆæœã€‚")

# --- è¼‰å…¥æ¨¡å‹å’Œè³‡æ–™ ---
@st.cache_resource
def load_model_and_data():
    # æª¢æŸ¥æ¨¡å‹æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if not os.path.exists('models/spam_model.pkl') or not os.path.exists('models/vectorizer.pkl'):
        st.error("æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆï¼è«‹å…ˆåŸ·è¡Œ `train_model.py` ä¾†è¨“ç·´ä¸¦å„²å­˜æ¨¡å‹ã€‚")
        st.stop()
    
    model = joblib.load("models/spam_model.pkl")
    vectorizer = joblib.load("models/vectorizer.pkl")
    
    # æª¢æŸ¥è³‡æ–™æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if not os.path.exists('data/sms_spam_no_header.csv'):
        st.error("æ‰¾ä¸åˆ°è³‡æ–™æª”æ¡ˆï¼è«‹å…ˆåŸ·è¡Œ `train_model.py` ä¾†ä¸‹è¼‰è³‡æ–™ã€‚")
        st.stop()
        
    df = pd.read_csv("data/sms_spam_no_header.csv", names=["label", "message"])
    return model, vectorizer, df

model, vectorizer, df = load_model_and_data()

# --- åŠŸèƒ½ 1: éš¨æ©ŸæŠ½æ¨£èˆ‡é æ¸¬ ---
st.header("âœ‰ï¸ éš¨æ©ŸæŠ½æ¨£æ¸¬è©¦")

if 'random_message' not in st.session_state:
    st.session_state.random_message = ""

if st.button("å¾è³‡æ–™é›†ä¸­éš¨æ©Ÿé¸æ“‡ä¸€ç­†"):
    random_sample = df.sample(n=1).iloc[0]
    st.session_state.random_message = random_sample["message"]
    st.info(f"**æŠ½æ¨£å…§å®¹ï¼š** {st.session_state.random_message}")
    st.info(f"**çœŸå¯¦æ¨™ç±¤ï¼š** {'åƒåœ¾éƒµä»¶ (Spam)' if random_sample['label'] == 'spam' else 'æ­£å¸¸éƒµä»¶ (Ham)'}")

# --- åŠŸèƒ½ 2: æ‰‹å‹•è¼¸å…¥é æ¸¬ ---
st.header("âœï¸ è‡ªè¡Œè¼¸å…¥æ–‡å­—é æ¸¬")

# ä½¿ç”¨ session_state ä¸­çš„å€¼ä¾†è¨­å®š text_area
user_input = st.text_area("è«‹åœ¨ä¸‹æ–¹è²¼ä¸Šæˆ–è¼¸å…¥æ‚¨æƒ³é æ¸¬çš„éƒµä»¶å…§å®¹ï¼š", st.session_state.random_message, height=150)

if st.button("é–‹å§‹é æ¸¬"):
    if user_input.strip() == "":
        st.warning("è«‹è¼¸å…¥æœ‰æ•ˆçš„æ–‡å­—å…§å®¹ï¼")
    else:
        # 1. å‰è™•ç†
        processed_input = user_input.lower().translate(str.maketrans('', '', string.punctuation))
        
        # 2. å‘é‡åŒ–
        vectorized_input = vectorizer.transform([processed_input])
        
        # 3. é æ¸¬
        prediction = model.predict(vectorized_input)[0]
        prediction_proba = model.predict_proba(vectorized_input)[0]

        # 4. é¡¯ç¤ºçµæœ
        st.subheader("é æ¸¬çµæœ")
        if prediction == "spam":
            spam_probability = prediction_proba[1] * 100
            st.error(f"é€™å°éƒµä»¶æœ‰ **{spam_probability:.2f}%** çš„å¯èƒ½æ€§æ˜¯ã€åƒåœ¾éƒµä»¶ã€‘ï¼")
        else:
            ham_probability = prediction_proba[0] * 100
            st.success(f"é€™å°éƒµä»¶æœ‰ **{ham_probability:.2f}%** çš„å¯èƒ½æ€§æ˜¯ã€æ­£å¸¸éƒµä»¶ã€‘ã€‚")

# --- åŠŸèƒ½ 3: é¡¯ç¤ºè¨“ç·´æˆæœèˆ‡å…§å®¹ ---
st.header("ğŸ“Š è¨“ç·´æˆæœèˆ‡è³‡æ–™é›†å…§å®¹")

with st.expander("é»æ“ŠæŸ¥çœ‹æ¨¡å‹è¨“ç·´æˆæœ"):
    st.write("æˆ‘å€‘ä½¿ç”¨ `Naive Bayes` æ¨¡å‹é€²è¡Œè¨“ç·´ï¼Œä»¥ä¸‹æ˜¯æ¨¡å‹çš„è¡¨ç¾ï¼š")
    st.text("æº–ç¢ºç‡ (Accuracy): 0.9856")
    st.text("""
                  precision    recall  f1-score   support

         ham       0.98      1.00      0.99       966
        spam       0.99      0.90      0.94       149

    avg / total       0.99      0.99      0.98      1115
    """)
    st.info("**åè©è§£é‡‹ï¼š**\n- **Precision (ç²¾ç¢ºç‡):** åœ¨æ‰€æœ‰è¢«é æ¸¬ç‚ºåƒåœ¾éƒµä»¶çš„éƒµä»¶ä¸­ï¼Œæœ‰å¤šå°‘æ˜¯çœŸçš„åƒåœ¾éƒµä»¶ã€‚\n- **Recall (å¬å›ç‡):** åœ¨æ‰€æœ‰çœŸçš„åƒåœ¾éƒµä»¶ä¸­ï¼Œæœ‰å¤šå°‘è¢«æˆåŠŸé æ¸¬å‡ºä¾†ã€‚\n- **F1-score:** Precision å’Œ Recall çš„èª¿å’Œå¹³å‡æ•¸ï¼Œæ˜¯å€‹ç¶œåˆæŒ‡æ¨™ã€‚")

with st.expander("é»æ“ŠæŸ¥çœ‹åŸå§‹è³‡æ–™é›†"):
    st.dataframe(df)
